{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: ['Can', 'we', 'make', 'this', 'quick', 'Roxanne', 'Korrine', 'and', 'Andrew', 'Barrett', 'are', 'having', 'an', 'incredibly', 'horrendous', 'public', 'break', 'up', 'on', 'the', 'quad', 'Again']\n",
      "Decoded sentence: prisonerearlypurposedrugsprestigedoctordoctordoctorreasonTheirgroupwatchinglongconfidentialmercyPinzonPinzongenedoingreporterreadywhich\n",
      "-\n",
      "Input sentence: ['Well', 'I', 'thought', 'we', 'd', 'start', 'with', 'pronunciation', 'if', 'that', 's', 'okay', 'with', 'you']\n",
      "Decoded sentence: prisonerearlypurposedrugsprestigedoctordoctordoctorreasonTheirgroupwatchinglongconfidentialmercyPinzonPinzongenedoingreporterreadywhich\n",
      "-\n",
      "Input sentence: ['Not', 'the', 'hacking', 'and', 'gagging', 'and', 'spitting', 'part', 'Please']\n",
      "Decoded sentence: prisonerearlypurposedrugsprestigedoctordoctordoctorreasonTheirgroupwatchinglongconfidentialmercyPinzonPinzongenedoingreporterreadywhich\n",
      "-\n",
      "Input sentence: ['You', 're', 'asking', 'me', 'out', 'That', 's', 'so', 'cute', 'What', 's', 'your', 'name', 'again']\n",
      "Decoded sentence: prisonerearlypurposedrugsprestigedoctordoctordoctorreasonTheirgroupwatchinglongconfidentialmercyPinzonPinzongenedoingreporterreadywhich\n",
      "-\n",
      "Input sentence: ['No', 'no', 'it', 's', 'my', 'fault', 'we', 'didn', 't', 'have', 'a', 'proper', 'introduction']\n",
      "Decoded sentence: prisonerearlypurposedrugsprestigedoctordoctordoctorreasonTheirgroupwatchinglongconfidentialmercyPinzonPinzongenedoingreporterreadywhich\n",
      "-\n",
      "Input sentence: ['Cameron']\n",
      "Decoded sentence: prisonerearlypurposedrugsprestigedoctordoctordoctorreasonTheirgroupwatchinglongconfidentialmercyPinzonPinzongenedoingreporterreadywhich\n",
      "-\n",
      "Input sentence: ['The', 'thing', 'is', 'Cameron', 'I', 'm', 'at', 'the', 'mercy', 'of', 'a', 'particularly', 'hideous', 'breed', 'of', 'loser', 'My', 'sister', 'I', 'can', 't', 'date', 'until', 'she', 'does']\n",
      "Decoded sentence: prisonerearlypurposedrugsprestigedoctordoctordoctorreasonTheirgroupwatchinglongconfidentialmercyPinzonPinzongenedoingreporterreadywhich\n",
      "-\n",
      "Input sentence: ['Why']\n",
      "Decoded sentence: prisonerearlypurposedrugsprestigedoctordoctordoctorreasonTheirgroupwatchinglongconfidentialmercyPinzonPinzongenedoingreporterreadywhich\n",
      "-\n",
      "Input sentence: ['Unsolved', 'mystery', 'She', 'used', 'to', 'be', 'really', 'popular', 'when', 'she', 'started', 'high', 'school', 'then', 'it', 'was', 'just', 'like', 'she', 'got', 'sick', 'of', 'it', 'or', 'something']\n",
      "Decoded sentence: prisonerearlypurposedrugsprestigedoctordoctordoctorreasonTheirgroupwatchinglongconfidentialmercyPinzonPinzongenedoingreporterreadywhich\n",
      "-\n",
      "Input sentence: ['Gosh', 'if', 'only', 'we', 'could', 'find', 'Kat', 'a', 'boyfriend']\n",
      "Decoded sentence: prisonerearlypurposedrugsprestigedoctordoctordoctorreasonTheirgroupwatchinglongconfidentialmercyPinzonPinzongenedoingreporterreadywhich\n",
      "-\n",
      "Input sentence: ['C', 'esc', 'ma', 'tete', 'This', 'is', 'my', 'head']\n",
      "Decoded sentence: prisonerearlypurposedrugsprestigedoctordoctordoctorreasonTheirgroupwatchinglongconfidentialmercyPinzonPinzongenedoingreporterreadywhich\n",
      "-\n",
      "Input sentence: ['Right', 'See', 'You', 're', 'ready', 'for', 'the', 'quiz']\n",
      "Decoded sentence: prisonerearlypurposedrugsprestigedoctordoctordoctorreasonTheirgroupwatchinglongconfidentialmercyPinzonPinzongenedoingreporterreadywhich\n",
      "-\n",
      "Input sentence: ['I', 'don', 't', 'want', 'to', 'know', 'how', 'to', 'say', 'that', 'though', 'I', 'want', 'to', 'know', 'useful', 'things', 'Like', 'where', 'the', 'good', 'stores', 'are', 'How', 'much', 'does', 'champagne', 'cost', 'Stuff', 'like', 'Chat', 'I', 'have', 'never', 'in', 'my', 'life', 'had', 'to', 'point', 'out', 'my', 'head', 'to', 'someone']\n",
      "Decoded sentence: prisonerearlypurposedrugsprestigedoctordoctordoctorreasonTheirgroupwatchinglongconfidentialmercyPinzonPinzongenedoingreporterreadywhich\n",
      "-\n",
      "Input sentence: ['That', 's', 'because', 'it', 's', 'such', 'a', 'nice', 'one']\n",
      "Decoded sentence: prisonerearlypurposedrugsprestigedoctordoctordoctorreasonTheirgroupwatchinglongconfidentialmercyPinzonPinzongenedoingreporterreadywhich\n",
      "-\n",
      "Input sentence: ['How', 'is', 'our', 'little', 'Find', 'the', 'Wench', 'A', 'Date', 'plan', 'progressing']\n",
      "Decoded sentence: prisonerearlypurposedrugsprestigedoctordoctordoctorreasonTheirgroupwatchinglongconfidentialmercyPinzonPinzongenedoingreporterreadywhich\n",
      "-\n",
      "Input sentence: ['There']\n",
      "Decoded sentence: prisonerearlypurposedrugsprestigedoctordoctordoctorreasonTheirgroupwatchinglongconfidentialmercyPinzonPinzongenedoingreporterreadywhich\n",
      "-\n",
      "Input sentence: ['You', 'got', 'something', 'on', 'your', 'mind']\n",
      "Decoded sentence: prisonerearlypurposedrugsprestigedoctordoctordoctorreasonTheirgroupwatchinglongconfidentialmercyPinzonPinzongenedoingreporterreadywhich\n",
      "-\n",
      "Input sentence: ['You', 'have', 'my', 'word', 'As', 'a', 'gentleman']\n",
      "Decoded sentence: prisonerearlypurposedrugsprestigedoctordoctordoctorreasonTheirgroupwatchinglongconfidentialmercyPinzonPinzongenedoingreporterreadywhich\n",
      "-\n",
      "Input sentence: ['How', 'do', 'you', 'get', 'your', 'hair', 'to', 'look', 'like', 'that']\n",
      "Decoded sentence: prisonerearlypurposedrugsprestigedoctordoctordoctorreasonTheirgroupwatchinglongconfidentialmercyPinzonPinzongenedoingreporterreadywhich\n",
      "-\n",
      "Input sentence: ['Sure', 'have']\n",
      "Decoded sentence: prisonerearlypurposedrugsprestigedoctordoctordoctorreasonTheirgroupwatchinglongconfidentialmercyPinzonPinzongenedoingreporterreadywhich\n",
      "-\n",
      "Input sentence: ['I', 'really', 'really', 'really', 'wanna', 'go', 'but', 'I', 'can', 't', 'Not', 'unless', 'my', 'sister', 'goes']\n",
      "Decoded sentence: prisonerearlypurposedrugsprestigedoctordoctordoctorreasonTheirgroupwatchinglongconfidentialmercyPinzonPinzongenedoingreporterreadywhich\n",
      "-\n",
      "Input sentence: ['She', 's', 'not', 'a']\n",
      "Decoded sentence: prisonerearlypurposedrugsprestigedoctordoctordoctorreasonTheirgroupwatchinglongconfidentialmercyPinzonPinzongenedoingreporterreadywhich\n",
      "-\n",
      "Input sentence: ['Lesbian', 'No', 'I', 'found', 'a', 'picture', 'of', 'Jared', 'Leto', 'in', 'one', 'of', 'her', 'drawers', 'so', 'I', 'm', 'pretty', 'sure', 'she', 's', 'not', 'harboring', 'same', 'sex', 'tendencies']\n",
      "Decoded sentence: prisonerearlypurposedrugsprestigedoctordoctordoctorreasonTheirgroupwatchinglongconfidentialmercyPinzonPinzongenedoingreporterreadywhich\n",
      "-\n",
      "Input sentence: ['So', 'that', 's', 'the', 'kind', 'of', 'guy', 'she', 'likes', 'Pretty', 'ones']\n",
      "Decoded sentence: prisonerearlypurposedrugsprestigedoctordoctordoctorreasonTheirgroupwatchinglongconfidentialmercyPinzonPinzongenedoingreporterreadywhich\n",
      "-\n",
      "Input sentence: ['Hi']\n",
      "Decoded sentence: prisonerearlypurposedrugsprestigedoctordoctordoctorreasonTheirgroupwatchinglongconfidentialmercyPinzonPinzongenedoingreporterreadywhich\n",
      "-\n",
      "Input sentence: ['You', 'know', 'Chastity']\n",
      "Decoded sentence: prisonerearlypurposedrugsprestigedoctordoctordoctorreasonTheirgroupwatchinglongconfidentialmercyPinzonPinzongenedoingreporterreadywhich\n",
      "-\n",
      "Input sentence: ['Have', 'fun', 'tonight']\n",
      "Decoded sentence: prisonerearlypurposedrugsprestigedoctordoctordoctorreasonTheirgroupwatchinglongconfidentialmercyPinzonPinzongenedoingreporterreadywhich\n",
      "-\n",
      "Input sentence: ['I', 'looked', 'for', 'you', 'back', 'at', 'the', 'party', 'but', 'you', 'always', 'seemed', 'to', 'be', 'occupied']\n",
      "Decoded sentence: prisonerearlypurposedrugsprestigedoctordoctordoctorreasonTheirgroupwatchinglongconfidentialmercyPinzonPinzongenedoingreporterreadywhich\n",
      "-\n",
      "Input sentence: ['I', 'was']\n",
      "Decoded sentence: prisonerearlypurposedrugsprestigedoctordoctordoctorreasonTheirgroupwatchinglongconfidentialmercyPinzonPinzongenedoingreporterreadywhich\n",
      "-\n",
      "Input sentence: ['Well', 'no']\n",
      "Decoded sentence: prisonerearlypurposedrugsprestigedoctordoctordoctorreasonTheirgroupwatchinglongconfidentialmercyPinzonPinzongenedoingreporterreadywhich\n",
      "-\n",
      "Input sentence: ['Then', 'that', 's', 'all', 'you', 'had', 'to', 'say']\n",
      "Decoded sentence: prisonerearlypurposedrugsprestigedoctordoctordoctorreasonTheirgroupwatchinglongconfidentialmercyPinzonPinzongenedoingreporterreadywhich\n",
      "-\n",
      "Input sentence: ['But']\n",
      "Decoded sentence: prisonerearlypurposedrugsprestigedoctordoctordoctorreasonTheirgroupwatchinglongconfidentialmercyPinzonPinzongenedoingreporterreadywhich\n",
      "-\n",
      "Input sentence: ['Then', 'Guillermo', 'says', 'If', 'you', 'go', 'any', 'lighter', 'you', 're', 'gonna', 'look', 'like', 'an', 'extra', 'on', '90210']\n",
      "Decoded sentence: prisonerearlypurposedrugsprestigedoctordoctordoctorreasonTheirgroupwatchinglongconfidentialmercyPinzonPinzongenedoingreporterreadywhich\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: ['do', 'you', 'listen', 'to', 'this', 'crap']\n",
      "Decoded sentence: prisonerearlypurposedrugsprestigedoctordoctordoctorreasonTheirgroupwatchinglongconfidentialmercyPinzonPinzongenedoingreporterreadywhich\n",
      "-\n",
      "Input sentence: ['What', 'crap']\n",
      "Decoded sentence: prisonerearlypurposedrugsprestigedoctordoctordoctorreasonTheirgroupwatchinglongconfidentialmercyPinzonPinzongenedoingreporterreadywhich\n",
      "-\n",
      "Input sentence: ['Me', 'This', 'endless', 'blonde', 'babble', 'I', 'm', 'like', 'boring', 'myself']\n",
      "Decoded sentence: prisonerearlypurposedrugsprestigedoctordoctordoctorreasonTheirgroupwatchinglongconfidentialmercyPinzonPinzongenedoingreporterreadywhich\n",
      "-\n",
      "Input sentence: ['I', 'figured', 'you', 'd', 'get', 'to', 'the', 'good', 'stuff', 'eventually']\n",
      "Decoded sentence: prisonerearlypurposedrugsprestigedoctordoctordoctorreasonTheirgroupwatchinglongconfidentialmercyPinzonPinzongenedoingreporterreadywhich\n",
      "-\n",
      "Input sentence: ['What', 'good', 'stuff']\n",
      "Decoded sentence: prisonerearlypurposedrugsprestigedoctordoctordoctorreasonTheirgroupwatchinglongconfidentialmercyPinzonPinzongenedoingreporterreadywhich\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-08084cac6a3f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[1;31m# for trying out decoding.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[0minput_seq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder_input_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mseq_index\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mseq_index\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m     \u001b[0mdecoded_sentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecode_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'-'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Input sentence:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_texts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mseq_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-08084cac6a3f>\u001b[0m in \u001b[0;36mdecode_sequence\u001b[1;34m(input_seq)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mstop_condition\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         output_tokens, h, c = decoder_model.predict(\n\u001b[1;32m---> 86\u001b[1;33m             [target_seq] + states_value)\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[1;31m# Sample a token\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1167\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1168\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1169\u001b[1;33m                                             steps=steps)\n\u001b[0m\u001b[0;32m   1170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1171\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[1;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 294\u001b[1;33m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "encoder_inputs = Input(shape=(None, 2008))\n",
    "model = load_model('s2s.h5')\n",
    "\n",
    "# Next: inference mode (sampling).\n",
    "# Here's the drill:\n",
    "# 1) encode input and retrieve initial decoder state\n",
    "# 2) run one step of decoder with this initial state\n",
    "# and a \"start of sequence\" token as target.\n",
    "# Output will be the next target token\n",
    "# 3) Repeat with the current target token and current states\n",
    "# Define an input sequence and process it.\n",
    "batch_size = 64  # Batch size for training.\n",
    "epochs = 2  # Number of epochs to train for.\n",
    "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
    "num_samples = 10000  # Number of samples to train on.\n",
    "\n",
    "num_encoder_tokens = 2008\n",
    "num_decoder_tokens = 1981\n",
    "max_encoder_seq_length = 106\n",
    "max_decoder_seq_length = 131\n",
    "\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define sampling models\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "\n",
    "\n",
    "input_token_index = np.load('input_token_index.npy').item()\n",
    "target_token_index = np.load('target_token_index.npy').item()\n",
    "with open('input_texts.pickle', 'rb') as f:\n",
    "        input_texts = pickle.load(f)\n",
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())\n",
    "\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, 0] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "\n",
    "for seq_index in range(100):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
